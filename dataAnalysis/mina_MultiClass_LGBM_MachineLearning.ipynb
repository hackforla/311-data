{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook displays end-to-end machine learning process: \n",
    "\n",
    "1) data cleaning, \n",
    "\n",
    "2) data processing & feature engineering, \n",
    "\n",
    "3) model building \n",
    "\n",
    "The majority of work involves extensive data cleaning and engineering:\n",
    "\n",
    "- various datasets (2015-2019)\n",
    "- geodata and time series \n",
    "- RequestType is used as the dependent variable to setup for multi-class classification task\n",
    "- where(zipcodes/districts/neighborhoods) vs when(days difference/date categories) vs what RequestType\n",
    "- final clean dataframe is sorted by ascending CreatedDate\n",
    "- LGBMClassifier is used and tested on validation set \n",
    "- only around 0.06 in multi-logloss for this first round of testing \n",
    "- about 0.02 small difference between train and validation sets; thus, no overfitting issue\n",
    "- tested with CatboostClassifier as well; however, due to slow running time and memory issue, only included LGBM here.\n",
    "\n",
    "For data analysis part, please refer to my previous work as well:\n",
    "\n",
    "https://github.com/hackforla/311-data/blob/dev/dataAnalysis/minaAnalysis_311data.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import auc,roc_auc_score\n",
    "from catboost import CatBoostClassifier,Pool, cv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from datetime import time\n",
    "import gc\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "import matplotlib.gridspec as gridspec\n",
    "import geopandas\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(237305, 33) (952486, 33) (1131558, 33) (1210075, 33) (1308093, 34)\n"
     ]
    }
   ],
   "source": [
    "df_19=pd.read_csv('../input/datafolder/MyLA311_Service_Request_Data_2019.csv')\n",
    "df_15=pd.read_csv('../input/la3111-data/MyLA311_Service_Request_Data_2015.csv')\n",
    "df_16=pd.read_csv('../input/la3111-data/MyLA311_Service_Request_Data_2016.csv')\n",
    "df_17=pd.read_csv('../input/la3111-data/MyLA311_Service_Request_Data_2017.csv')\n",
    "df_18=pd.read_csv('../input/la3111-data/MyLA311_Service_Request_Data_2018.csv')\n",
    "print(df_15.shape, df_16.shape, df_17.shape, df_18.shape, df_19.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1308093, 33)\n"
     ]
    }
   ],
   "source": [
    "df_19.drop(['CreatedByUserOrganization'], axis=1, inplace=True)\n",
    "print(df_19.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4839517, 32)\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df_15, df_16, df_17, df_18, df_19])\n",
    "df.drop(['HouseNumber', #'Latitude', 'Longitude'\n",
    "        ], axis=1, inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del [[df_15, df_16, df_17, df_18, df_19]]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4576273, 32)\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "df = df[df['ServiceDate'].notnull()]\n",
    "df = df[df['ClosedDate'].notnull()]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "df['CreatedDate'] = pd.to_datetime(df['CreatedDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['UpdatedDate'] = pd.to_datetime(df['UpdatedDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ServiceDate'] = pd.to_datetime(df['ServiceDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ClosedDate'] = pd.to_datetime(df['ClosedDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['service']= (df['ServiceDate']).astype('str').str.slice(stop=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4575985, 33)\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "df = df[~df['service'].str.startswith(('1900', '2109', '2107', '2027', '2026', '2022',\n",
    "                                       '2007', '2012', '2013', '2014',\n",
    "                                     '2020-12', '2020-11', '2020-10', '2020-09',\n",
    "                                     '2020-08', '2020-07', '2020-06', '2020-05', '2020-04',\n",
    "                                     '2015-01', '2015-02', '2015-03', '2015-04',\n",
    "                                     '2015-05', '2015-06', '2015-07', '2015-08-05'\n",
    "                                    ))]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "df['ClosedCreatedDiff'] = df['ClosedDate'] - df['CreatedDate']\n",
    "df['ServiceCreatedDiff'] = df['ServiceDate'] - df['CreatedDate']\n",
    "df['ClosedServiceDiff'] = df['ClosedDate'] - df['ServiceDate']\n",
    "\n",
    "df['UpdatedCreatedDiff'] = df['UpdatedDate'] - df['CreatedDate']\n",
    "df['UpdatedServiceDiff'] = df['UpdatedDate'] - df['ServiceDate']\n",
    "df['UpdatedClosedDiff'] = df['UpdatedDate'] - df['ClosedDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "def ddiff2days(ddiff):\n",
    "    if not pd.isnull(ddiff):\n",
    "        return pd.Timedelta.total_seconds(ddiff)/(24.*3600)\n",
    "    else:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "cols = ['ClosedCreatedDiff', 'ServiceCreatedDiff', 'ClosedServiceDiff', \n",
    "   'UpdatedCreatedDiff', 'UpdatedServiceDiff', 'UpdatedClosedDiff']\n",
    "for c in cols:\n",
    "    df[c] = df[c].apply(ddiff2days)\n",
    "    df[c] = df[c].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3549977, 39)\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "df = df[df['ServiceCreatedDiff'] > 0.00]\n",
    "df = df[df['ClosedServiceDiff'] > 0.00]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Data Processing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3549967, 39)\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "df['Address'] = df['Address'].str.lower()\n",
    "df['Address'] = df['Address'].str.replace(',','')\n",
    "df = df[df['Address'].notnull()]\n",
    "df['Address'] = df['Address'].str.replace('1  ', '1 ')\n",
    "df['Address'] = df['Address'].str.replace('1/2 ', '')\n",
    "df['Address'] = df['Address'].str.replace('at ', '')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9\n",
    "import re\n",
    "df['st_1'] = df['Address'].str.extract('([a-zA-Z ]+)', expand=False).str.strip()\n",
    "df['st_1'] = (df['st_1'].replace('','Unknown')).astype('object')\n",
    "df['First'] = df['st_1'].str.split('\\s+').str[0]\n",
    "df['Third'] = df['st_1'].str.split('\\s+').str[-1]\n",
    "df['zip'] = df['Address'].str.extract(r'(\\d{5}\\-?\\d{0,4})')\n",
    "df['zip'] = df['zip'].str.slice(stop=5)\n",
    "df.drop(['ZipCode', 'service'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "cols = ['Direction', 'StreetName', 'Suffix',\n",
    "        'MobileOS', 'AssignTo', 'ApproximateAddress',\n",
    "        'Location', 'TBMColumn', 'APC', \n",
    "        'CDMember', 'NCName', 'PolicePrecinct']\n",
    "for c in cols:\n",
    "    df[c].fillna('unknown', inplace=True)\n",
    "    df[c] = df[c].astype('object')\n",
    "\n",
    "df['NC'].fillna(999.0, inplace=True)\n",
    "df['TBMPage'].fillna(999.0, inplace=True)\n",
    "df['CD'].fillna(99.0, inplace=True)\n",
    "df['TBMRow'].fillna(99.0, inplace=True)\n",
    "df['zip'].fillna('99999', inplace=True)\n",
    "\n",
    "cols = ['NC', 'TBMPage', 'CD', 'TBMRow', 'zip']\n",
    "for c in cols:\n",
    "    df[c] = df[c].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "df['NCName'] = df['NCName'].str.lower()\n",
    "df['NCName'] = df['NCName'].astype('str').str.replace('nc', '').str.replace('cc', '').str.replace('ndc', '').str.replace('p.i.c.o.', 'pico union')\n",
    "df['TBMColumn'] = df['TBMColumn'].astype('str').str.replace('unknown','A').str.replace('I','A')\n",
    "df['assign'] = df['AssignTo'].str.extract('([a-zA-Z ]+)', expand=False).str.strip()\n",
    "df['assign'] = df['assign'].astype('str').str.replace('SSC Residential', 'unknown').str.replace('LSD', 'unknown')\n",
    "df.drop(['AssignTo'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12\n",
    "df['Direction'] = (df['Direction'].map({\n",
    "'W': 'W', 'N': 'N', 'S': 'S', 'E': 'E', 'unknown': 'W', 'WEST': 'W', 'R': 'W', 'NORTH': 'N',\n",
    "'SHELDON': 'W', 'EXPOSITION': 'W', 'BURBANK': 'W', 'SOUTH': 'S',\n",
    "'ELYSIAN': 'W', 'CORBIN': 'W', 'VAN': 'W', 'VICTORY': 'W',\n",
    "'HOMER': 'W', 'ARLETA': 'W', 'WORTH': 'W', 'SAN': 'W',\n",
    "'ALLEGHENY': 'W', 'TOBERMAN': 'W', 'SANTA': 'W', 'FALLBROOK': 'W',\n",
    "'UNIVERSAL': 'W', 'CLEAR': 'W', 'RESEDA': 'W',\n",
    "})).astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#13\n",
    "df['Suffix'] = (df['Suffix'].map({\n",
    "'AVE': 'ave', 'ST': 'st', 'BLVD': 'blvd', 'unknown': 'unknown', 'DR': 'dr', 'PL': 'pl',\n",
    "'WAY': 'wy', 'ROAD': 'rd', 'LANE': 'ln', 'TER': 'ter', 'CT': 'ct', 'AV': 'ave',\n",
    "'CIR': 'ct', 'HWY': 'wy', 'RD': 'rd', 'WALK': 'wy', 'TR': 'ter', 'GRN': 'ct',        \n",
    "'LN': 'ln', 'WY': 'wy', 'MALL': 'wy', 'CL': 'ct', 'PARK': 'wy', 'WK': 'wy',\n",
    "'PKWY': 'wy', 'CK': 'ct', 'VISTA': 'unknown', 'HILL': 'unknown', 'PASS': 'unknown', 'VIS': 'unknown',\n",
    "'COVE': 'unknown', 'CYN': 'unknown', 'ROW': 'unknown', 'PT': 'unknown', 'AL': 'unknown', 'SQ': 'unknown',\n",
    "'PZ': 'unknown', 'PASEO': 'unknown', 'RDG': 'unknown', 'VIEW': 'unknown', 'VIA': 'unknown', 'SP': 'unknown',\n",
    "'HL': 'unknown', 'VW': 'unknown', 'CV': 'unknown'\n",
    "})).astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14\n",
    "action = []\n",
    "#For each row in the column,\n",
    "for row in df['ActionTaken']:\n",
    "    if row == 'SR Created':\n",
    "        action.append('SR Created')\n",
    "    else:\n",
    "        action.append('Others')\n",
    "\n",
    "df['action'] = action\n",
    "df['action'] = (df['action']).astype('object')\n",
    "df.drop(['ActionTaken'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15\n",
    "own = []\n",
    "for row in df['Owner']:\n",
    "    if row == 'RAP':\n",
    "        own.append('BOS')\n",
    "    else:\n",
    "        own.append(row)\n",
    "df['own'] = own\n",
    "df['own'] = (df['own']).astype('object')\n",
    "df.drop(['Owner'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16\n",
    "source= []\n",
    "for row in df['RequestSource']:\n",
    "    if row == 'Call':\n",
    "        source.append('Call')\n",
    "    elif row == 'Mobile App':\n",
    "        source.append('Mobile App')\n",
    "    elif row == 'Self Service':\n",
    "        source.append('Self Service')\n",
    "    elif row == 'Email':\n",
    "        source.append('Email')\n",
    "    else:\n",
    "        source.append('Mobile App')\n",
    "        \n",
    "df['source'] = source\n",
    "df['source'] = (df['source']).astype('object')\n",
    "df.drop(['RequestSource', 'Address', # 'NCName', 'own', 'action'\n",
    "        ], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#17\n",
    "df['created_year'] = (df['CreatedDate'].dt.year).astype('int16')\n",
    "df['created_month'] = (df['CreatedDate'].dt.month).astype('int16')\n",
    "df['created_hour'] = (df['CreatedDate'].dt.hour).astype('int16')\n",
    "df['created_week'] = (df['CreatedDate'].dt.week).astype('int16')\n",
    "df['created_dayofweek'] = (df['CreatedDate'].dt.dayofweek).astype('int16')\n",
    "df['created_weekend'] = (np.where(np.logical_or(df['created_dayofweek'] == 5,\n",
    "                                               df['created_dayofweek'] == 6), 1, 0)).astype('int16')\n",
    "df['service_year'] = (df['ServiceDate'].dt.year).astype('int16')\n",
    "df['service_month'] = (df['ServiceDate'].dt.month).astype('int16')\n",
    "df['service_week'] = (df['ServiceDate'].dt.week).astype('int16')\n",
    "\n",
    "df['closed_year'] = (df['ClosedDate'].dt.year).astype('int16')\n",
    "df['closed_month'] = (df['ClosedDate'].dt.month).astype('int16')\n",
    "df['closed_week'] = (df['ClosedDate'].dt.week).astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#18\n",
    "df['oversixmonths_closedcreated'] = (np.where(df['ClosedCreatedDiff']> 180.00, 1, 0)).astype('int8')\n",
    "df['overthreemonths_closedservice'] = (np.where(df['ClosedServiceDiff']> 120.00, 1, 0)).astype('int8')\n",
    "df['overthreemonths_servicecreated'] = (np.where(df['ServiceCreatedDiff']> 120.00, 1, 0)).astype('int8')\n",
    "df['oversixmonths_updatedcreated'] = (np.where(df['UpdatedCreatedDiff']> 180.00, 1, 0)).astype('int8')\n",
    "df['overthreemonths_updatedservice'] = (np.where(df['UpdatedServiceDiff']> 120.00, 1, 0)).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#19\n",
    "cols = ['ClosedCreatedDiff', 'ServiceCreatedDiff', 'ClosedServiceDiff', \n",
    "        'UpdatedCreatedDiff', \n",
    "       ]\n",
    "for c in cols:\n",
    "    df['max_zipcd_'+c]=(df.groupby(['zip', 'CD'])[c].transform('max')).astype('float32')\n",
    "    df['max_zip_'+c]=(df.groupby(['zip', 'CD', 'RequestType'])[c].transform('max')).astype('float32')\n",
    "    df['max_zipsourequest_'+c]=(df.groupby(['zip', 'RequestType'])[c].transform('max')).astype('float32')\n",
    "    \n",
    "    df['max_zipassign_'+c]=(df.groupby(['zip', 'assign'])[c].transform('max')).astype('float32')\n",
    "    df['max_st1assign_'+c]=(df.groupby(['st_1', 'assign'])[c].transform('max')).astype('float32')\n",
    "    df['max_firstassign_'+c]=(df.groupby(['First', 'assign'])[c].transform('max')).astype('float32')\n",
    "    df['max_thirdassign_'+c]=(df.groupby(['Third', 'assign'])[c].transform('max')).astype('float32')\n",
    "    df['max_Locationassign_'+c]=(df.groupby(['Location', 'assign'])[c].transform('max')).astype('float32')\n",
    "    \n",
    "    df['max_st1cd_'+c]=(df.groupby(['st_1', 'CD'])[c].transform('max')).astype('float32')\n",
    "    df['max_firstcd_'+c]=(df.groupby(['First', 'CD'])[c].transform('max')).astype('float32')\n",
    "    df['max_thirdcd_'+c]=(df.groupby(['Third', 'CD'])[c].transform('max')).astype('float32')\n",
    "    df['max_Locationcd_'+c]=(df.groupby(['Location', 'CD'])[c].transform('max')).astype('float32')\n",
    "    \n",
    "    df['max_st1type_'+c]=(df.groupby(['st_1', 'RequestType'])[c].transform('max')).astype('float32')\n",
    "    df['max_firsttype_'+c]=(df.groupby(['First', 'RequestType'])[c].transform('max')).astype('float32')\n",
    "    df['max_thirdtype_'+c]=(df.groupby(['Third', 'RequestType'])[c].transform('max')).astype('float32')\n",
    "    df['max_Locationtype_'+c]=(df.groupby(['Location', 'RequestType'])[c].transform('max')).astype('float32')\n",
    "    \n",
    "    df['max_zipnc_'+c]=(df.groupby(['zip', 'NC'])[c].transform('max')).astype('float32')\n",
    "    df['max_st1nc_'+c]=(df.groupby(['st_1', 'NC'])[c].transform('max')).astype('float32')\n",
    "    df['max_firstnc_'+c]=(df.groupby(['First', 'NC'])[c].transform('max')).astype('float32')\n",
    "    df['max_thirdnc_'+c]=(df.groupby(['Third', 'NC'])[c].transform('max')).astype('float32')\n",
    "    df['max_Locationnc_'+c]=(df.groupby(['Location', 'NC'])[c].transform('max')).astype('float32')\n",
    "    \n",
    "    df['max_zipapc_'+c]=(df.groupby(['zip', 'APC'])[c].transform('max')).astype('float32')\n",
    "    df['max_st1apc_'+c]=(df.groupby(['st_1', 'APC'])[c].transform('max')).astype('float32')\n",
    "    df['max_firstapc_'+c]=(df.groupby(['First', 'APC'])[c].transform('max')).astype('float32')\n",
    "    df['max_thirdapc_'+c]=(df.groupby(['Third', 'APC'])[c].transform('max')).astype('float32')\n",
    "    df['max_Locationapc_'+c]=(df.groupby(['Location', 'APC'])[c].transform('max')).astype('float32')\n",
    "    \n",
    "df.drop(['created_hour', 'created_dayofweek', 'created_weekend',\n",
    "'created_week', 'service_week', 'closed_week', \n",
    "], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20\n",
    "df['source_type'] = df['source'].astype('str')+'_'+df['RequestType'].astype('str')\n",
    "df['typesource_os'] = df['RequestType'].astype('str')+'_'+df['source'].astype('str')+df['MobileOS'].astype('str')\n",
    "df['verify_approx'] = df['AddressVerified'].astype('str')+'_'+df['ApproximateAddress'].astype('str')\n",
    "df['page_row_column'] = df['TBMPage'].astype('str')+'_'+df['TBMRow'].astype('str')+'_'+df['TBMColumn'].astype('str')\n",
    "\n",
    "df['pc_apc'] = df['PolicePrecinct'].astype('str')+'_'+df['APC'].astype('str')\n",
    "df['cd_member'] = df['CD'].astype('str')+'_'+df['CDMember'].astype('str')\n",
    "df['cd_assign'] = df['CD'].astype('str')+'_'+df['assign'].astype('str')\n",
    "df['cd_nc_pc'] = df['CD'].astype('str')+'_'+df['NC'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#21\n",
    "cols = ['ClosedCreatedDiff', 'ServiceCreatedDiff', 'ClosedServiceDiff', \n",
    "        'UpdatedCreatedDiff', #'UpdatedClosedDiff', \n",
    "        #'UpdatedServiceDiff'\n",
    "       ]\n",
    "for c in cols:\n",
    "    df['count_'+c] = (df[c].map(df[c].value_counts())).astype('int32')\n",
    "    \n",
    "del cols\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['max_zipnc_ClosedCreatedDiff', 'max_st1nc_ClosedCreatedDiff', \n",
    "         'max_firstnc_ClosedCreatedDiff', 'max_thirdnc_ClosedCreatedDiff', 'max_Locationnc_ClosedCreatedDiff',\n",
    "         'max_zipnc_ClosedServiceDiff', 'max_st1nc_ClosedServiceDiff', \n",
    "         'max_firstnc_ClosedServiceDiff', 'max_thirdnc_ClosedServiceDiff', 'max_Locationnc_ClosedServiceDiff',\n",
    "         'max_zipnc_ServiceCreatedDiff', 'max_st1nc_ServiceCreatedDiff', \n",
    "         'max_firstnc_ServiceCreatedDiff', 'max_thirdnc_ServiceCreatedDiff', 'max_Locationnc_ServiceCreatedDiff',\n",
    "        'max_zipapc_ClosedCreatedDiff', 'max_st1apc_ClosedCreatedDiff', \n",
    "         'max_firstapc_ClosedCreatedDiff', 'max_thirdapc_ClosedCreatedDiff', 'max_Locationapc_ClosedCreatedDiff',\n",
    "         'max_zipapc_ClosedServiceDiff', 'max_st1apc_ClosedServiceDiff', \n",
    "         'max_firstapc_ClosedServiceDiff', 'max_thirdapc_ClosedServiceDiff', 'max_Locationapc_ClosedServiceDiff',\n",
    "         'max_zipapc_ServiceCreatedDiff', 'max_st1apc_ServiceCreatedDiff', \n",
    "         'max_firstapc_ServiceCreatedDiff', 'max_thirdapc_ServiceCreatedDiff', 'max_Locationapc_ServiceCreatedDiff',        \n",
    "        'count_ClosedCreatedDiff', 'count_ServiceCreatedDiff', 'count_ClosedServiceDiff', \n",
    "        'count_UpdatedCreatedDiff',], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#22\n",
    "df['Status'] = (df['Status'].map({\n",
    "'Closed': 'closed',\n",
    "'Cancelled': 'cancelled',\n",
    "'Referred Out': 'Open',\n",
    "'Forward': 'open',\n",
    "'Open': 'open',\n",
    "'Pending': 'open'\n",
    "})).astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#23\n",
    "cols = [c for c in df.columns if df[c].dtypes=='object']\n",
    "for c in cols:\n",
    "    le = LabelEncoder()\n",
    "    df[c] = (le.fit_transform(df[c])).astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Model Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#24\n",
    "df.sort_values(by=['CreatedDate'], inplace=True, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3549967, 122) (3549967, 133) (3549967, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#25\n",
    "y = pd.DataFrame(df['Status'])\n",
    "X = df.drop(['CreatedDate',\n",
    "             'ServiceDate', 'UpdatedDate', 'ClosedDate', 'Status', \n",
    "             'NCName', 'action', 'own', \n",
    "             'StreetName', \n",
    "             #'Suffix', \n",
    "             #'First', 'Third',\n",
    "             'Latitude', 'Longitude',\n",
    "             #'pc_apc', 'cd_nc_pc',\n",
    "             #'page_row_column', \n",
    "             #'TBMPage', 'TBMColumn', 'TBMRow'\n",
    "            ], axis=1)\n",
    "print(X.shape, df.shape, y.shape)\n",
    "\n",
    "#del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2549967, 122) (1000000, 122) (2549967, 1) (1000000, 1)\n"
     ]
    }
   ],
   "source": [
    "#26\n",
    "X_train = X.iloc[:2549967]\n",
    "X_val = X.iloc[2549967:]\n",
    "y_train = y.iloc[:2549967]\n",
    "y_val = y.iloc[2549967:]\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.0548404\tvalid_1's multi_logloss: 0.0758155\n",
      "[200]\ttraining's multi_logloss: 0.0490642\tvalid_1's multi_logloss: 0.0689052\n",
      "[300]\ttraining's multi_logloss: 0.046885\tvalid_1's multi_logloss: 0.0666342\n",
      "[400]\ttraining's multi_logloss: 0.0457289\tvalid_1's multi_logloss: 0.0656381\n",
      "[500]\ttraining's multi_logloss: 0.0448872\tvalid_1's multi_logloss: 0.0650859\n",
      "[600]\ttraining's multi_logloss: 0.0442919\tvalid_1's multi_logloss: 0.0647865\n",
      "[700]\ttraining's multi_logloss: 0.0438255\tvalid_1's multi_logloss: 0.064601\n",
      "[800]\ttraining's multi_logloss: 0.0434253\tvalid_1's multi_logloss: 0.0644372\n",
      "[900]\ttraining's multi_logloss: 0.0431106\tvalid_1's multi_logloss: 0.0642786\n",
      "[1000]\ttraining's multi_logloss: 0.0428335\tvalid_1's multi_logloss: 0.0641462\n",
      "[1100]\ttraining's multi_logloss: 0.0425762\tvalid_1's multi_logloss: 0.0640373\n",
      "[1200]\ttraining's multi_logloss: 0.042357\tvalid_1's multi_logloss: 0.0638922\n",
      "[1300]\ttraining's multi_logloss: 0.0421361\tvalid_1's multi_logloss: 0.0638294\n",
      "[1400]\ttraining's multi_logloss: 0.0419376\tvalid_1's multi_logloss: 0.0637636\n",
      "[1500]\ttraining's multi_logloss: 0.0417418\tvalid_1's multi_logloss: 0.0636847\n",
      "[1600]\ttraining's multi_logloss: 0.0415625\tvalid_1's multi_logloss: 0.0636358\n",
      "[1700]\ttraining's multi_logloss: 0.0413878\tvalid_1's multi_logloss: 0.0636353\n",
      "[1800]\ttraining's multi_logloss: 0.0412241\tvalid_1's multi_logloss: 0.0635944\n",
      "[1900]\ttraining's multi_logloss: 0.0410612\tvalid_1's multi_logloss: 0.0635934\n",
      "[2000]\ttraining's multi_logloss: 0.0409118\tvalid_1's multi_logloss: 0.0635464\n",
      "[2100]\ttraining's multi_logloss: 0.0407694\tvalid_1's multi_logloss: 0.063544\n",
      "Early stopping, best iteration is:\n",
      "[2013]\ttraining's multi_logloss: 0.040893\tvalid_1's multi_logloss: 0.0635305\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = LGBMClassifier(\n",
    "                      objective='multiclass',\n",
    "                      n_estimators=4000,\n",
    "                      learning_rate=0.01,\n",
    "                      feature_fraction=0.2,\n",
    "                      bagging_fraction=0.2,\n",
    "                      min_data_in_leaf=13,\n",
    "                      max_depth=-1,\n",
    "                      num_leaves=20,\n",
    "                      early_stopping_rounds=100,\n",
    "                      bagging_freq=5,\n",
    "                      random_state=42,\n",
    "                     )\n",
    "\n",
    "lgb_clf.fit(X_train, y_train,\n",
    "      eval_set = [(X_train, y_train),(X_val, y_val.values)],\n",
    "      eval_metric = 'multiclass', \n",
    "      early_stopping_rounds = 100,\n",
    "      verbose = 100\n",
    "    )\n",
    "lgb_pred = lgb_clf.predict_proba(X_val)[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
